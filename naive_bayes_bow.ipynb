{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beauty = pd.read_csv(\"../data/beauty5k.csv\")\n",
    "beauty = beauty.dropna(subset=[\"reviewText\", \"overall\"])\n",
    "\n",
    "# encode sentiment to \"pos\" and \"neg\"\n",
    "# remove punctuation and tokenize reviewText\n",
    "def sentiment(x):\n",
    "    if x > 3.0:\n",
    "        return \"pos\"\n",
    "    return \"neg\"\n",
    "\n",
    "def remove_punc(s):\n",
    "    return s.translate(None, string.punctuation)\n",
    "\n",
    "def low(s):\n",
    "    return s.lower()\n",
    "\n",
    "beauty[\"sentiment\"] = beauty[\"overall\"].apply(sentiment)\n",
    "beauty[\"token\"] = beauty[\"reviewText\"].apply(low).apply(remove_punc).apply(word_tokenize)\n",
    "\n",
    "# POS tag\n",
    "beauty[\"tagged_token\"] = beauty[\"token\"].apply(nltk.pos_tag)\n",
    "\n",
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def token_remove_stop(token_list):\n",
    "    return [token for token in token_list if token not in stop]\n",
    "\n",
    "def tagged_token_remove_stop(list_tuple):\n",
    "    return [(token, tag) for (token, tag) in list_tuple if token not in stop]\n",
    "\n",
    "beauty[\"token_no_stop\"] = beauty[\"token\"].apply(token_remove_stop)\n",
    "beauty[\"tagged_token\"] = beauty[\"tagged_token\"].apply(tagged_token_remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token</th>\n",
       "      <th>tagged_token</th>\n",
       "      <th>token_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27677</td>\n",
       "      <td>A1ZNEYW8GJIF1P</td>\n",
       "      <td>B00006IV2F</td>\n",
       "      <td>Pat Sims</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Works well, no burning  fingers or neck like a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Value buy</td>\n",
       "      <td>1.382832e+09</td>\n",
       "      <td>10 27, 2013</td>\n",
       "      <td>pos</td>\n",
       "      <td>[works, well, no, burning, fingers, or, neck, ...</td>\n",
       "      <td>[(works, NNS), (well, RB), (burning, VBG), (fi...</td>\n",
       "      <td>[works, well, burning, fingers, neck, like, cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27716</td>\n",
       "      <td>A37V39UMYM2JIJ</td>\n",
       "      <td>B00006IV2F</td>\n",
       "      <td>rescueAdog</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Finally found a curling iron that does all tha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>1.329264e+09</td>\n",
       "      <td>02 15, 2012</td>\n",
       "      <td>pos</td>\n",
       "      <td>[finally, found, a, curling, iron, that, does,...</td>\n",
       "      <td>[(finally, RB), (found, VBD), (curling, NN), (...</td>\n",
       "      <td>[finally, found, curling, iron, promises, grea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      reviewerID        asin reviewerName helpful  \\\n",
       "0       27677  A1ZNEYW8GJIF1P  B00006IV2F     Pat Sims  [0, 0]   \n",
       "1       27716  A37V39UMYM2JIJ  B00006IV2F   rescueAdog  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall    summary  \\\n",
       "0  Works well, no burning  fingers or neck like a...      5.0  Value buy   \n",
       "1  Finally found a curling iron that does all tha...      5.0    Perfect   \n",
       "\n",
       "   unixReviewTime   reviewTime sentiment  \\\n",
       "0    1.382832e+09  10 27, 2013       pos   \n",
       "1    1.329264e+09  02 15, 2012       pos   \n",
       "\n",
       "                                               token  \\\n",
       "0  [works, well, no, burning, fingers, or, neck, ...   \n",
       "1  [finally, found, a, curling, iron, that, does,...   \n",
       "\n",
       "                                        tagged_token  \\\n",
       "0  [(works, NNS), (well, RB), (burning, VBG), (fi...   \n",
       "1  [(finally, RB), (found, VBD), (curling, NN), (...   \n",
       "\n",
       "                                       token_no_stop  \n",
       "0  [works, well, burning, fingers, neck, like, cu...  \n",
       "1  [finally, found, curling, iron, promises, grea...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beauty.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slipping', 'out', 'like', 'others', 'do']\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print beauty.iloc[1][\"token\"][-5:]\n",
    "print type(beauty.iloc[1][\"token_no_stop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(beauty, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "neg    2396\n",
      "pos    1603\n",
      "dtype: int64\n",
      "sentiment\n",
      "neg    603\n",
      "pos    397\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print train.groupby(\"sentiment\").size()\n",
    "print test.groupby(\"sentiment\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fabricate the format required by nltk.naivebayes\n",
    "train_token_label = []\n",
    "test_token_label = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    train_token_label += [(token, row[\"sentiment\"]) for token in row[\"token_no_stop\"]]\n",
    "for index, row in test.iterrows():\n",
    "    test_token_label += [(token, row[\"sentiment\"]) for token in row[\"token_no_stop\"]]\n",
    "    \n",
    "def nbfeature(token):\n",
    "    return {\"token\": token}\n",
    "\n",
    "train_feat = [(nbfeature(token), sent) for (token, sent) in train_token_label]\n",
    "test_feat = [(nbfeature(token), sent) for (token, sent) in test_token_label]\n",
    "\n",
    "train_x = [token for (token, sent) in train_feat]\n",
    "train_y = [sent for (token, sent) in train_feat]\n",
    "test_x = [token for (token, sent) in test_feat]\n",
    "test_y = [sent for (token, sent) in test_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token': 'covers'}, 'pos')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "nb_classifier = NaiveBayesClassifier.train(train_feat)\n",
    "nb_classifier.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6373919963619827"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(nb_classifier, test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Unigram, Bigram and Trigram in the feature\n",
    "from nltk.util import bigrams, trigrams\n",
    "\n",
    "train_token_label = []\n",
    "test_token_label = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    train_token_label += [(token, row[\"sentiment\"]) for token in row[\"token_no_stop\"]]\n",
    "    train_token_label += [(b, row[\"sentiment\"]) for b in list(bigrams(row[\"token_no_stop\"]))]\n",
    "    train_token_label += [(t, row[\"sentiment\"]) for t in list(trigrams(row[\"token_no_stop\"]))]\n",
    "for index, row in test.iterrows():\n",
    "    test_token_label += [(token, row[\"sentiment\"]) for token in row[\"token_no_stop\"]]\n",
    "    test_token_label += [(b, row[\"sentiment\"]) for b in list(bigrams(row[\"token_no_stop\"]))]\n",
    "    test_token_label += [(t, row[\"sentiment\"]) for t in list(trigrams(row[\"token_no_stop\"]))]\n",
    "    \n",
    "train_feat = [(nbfeature(token), sent) for (token, sent) in train_token_label]\n",
    "test_feat = [(nbfeature(token), sent) for (token, sent) in test_token_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650645526172\n"
     ]
    }
   ],
   "source": [
    "nb_classifier2 = NaiveBayesClassifier.train(train_feat)\n",
    "print nltk.classify.accuracy(nb_classifier2, test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# 5 fold bagging\n",
    "from sklearn.model_selection import KFold\n",
    "nb_5fold = []\n",
    "kf = KFold(n_splits=5, random_state=111, shuffle=True)\n",
    "for train_index, val_index in kf.split(train_feat):\n",
    "    train_data = [train_feat[index] for index in train_index]\n",
    "    nb = NaiveBayesClassifier.train(train_data)\n",
    "    nb_5fold.append(nb)\n",
    "print len(nb_5fold)\n",
    "\n",
    "\n",
    "# train_x = [token for (token, sent) in train_feat]\n",
    "# train_y = [sent for (token, sent) in train_feat]\n",
    "# test_x = [token for (token, sent) in test_feat]\n",
    "# test_y = [sent for (token, sent) in test_feat]\n",
    "\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# nb = NaiveBayesClassifier\n",
    "# nfold = 10\n",
    "# subsample = 0.9\n",
    "# nb_10fold = BaggingClassifier(base_estimator = nb,\n",
    "#                              n_estimators = nfold,\n",
    "#                              max_samples = subsample,\n",
    "#                              random_state = 111)\n",
    "\n",
    "# clf = nb_10fold.fit(train_x, train_y)\n",
    "# print clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for test_sample in test_feat:\n",
    "    pos_count, neg_count = 0, 0\n",
    "    for nb in nb_5fold:\n",
    "        pred = nb.classify(test_sample[0])\n",
    "        if pred == \"pos\":\n",
    "            pos_count += 1\n",
    "        else:\n",
    "            neg_count += 1\n",
    "    final_pred = \"pos\"\n",
    "    if pos_count < neg_count:\n",
    "        final_pred = \"neg\"\n",
    "    if final_pred == test_sample[1]:\n",
    "        accuracy += 1\n",
    "accuracy /= float(len(test_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650635775021\n"
     ]
    }
   ],
   "source": [
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
